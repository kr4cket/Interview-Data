# Вопросы

## GO

uintptr - целочисленное представление адрес в памяти (просто число)
unsafe.Pointer - указатель на объект абстрактного типа (можно привести к типу)

### Слайсы

Динамический массив - переменная длина

Представляет собой структуру sliceHeader:

* Len - длина слайса
* Cap - вместимость слайса (длина массива)
* Array - указатель на массив (указывает на первый элемент слайса)

При передаче в функцию нижлежащий массив передается по указателю, но len и cap по значению (append работает с тем же
массивом, но со своими len и cap)

append в случае превышения размера слайса (cap) увеличивает размер массива вдвое 1, 2, 4, ... (после 256 элементов
плавно переходит от 2 до 1.25 раз) и копирует все элементы в новый массив (изменяет указатель в слайсе на новый массив)

Операция взятия слайса `[start:end:max]` выставляет:

* start - индекс первого элемента слайса
* end - индекс элемента слайса следующим за последним
* max - индекс массива, до достижения которого слайс не будет выделяться новый массив (определяет capacity). По
  умолчанию указывает на конец массива. Нужен, например, чтобы нельзя было поменять значение массива при append

Функция copy копирует из одного слайса в другой, возвращает количество скопированных элементов

При использовании range sliceHeader копируется и изменения внутри цикла не приведет к изменению количества итераций

Массивы алоцируются на стеке, когда их размер <= 10MB, слайсы на стеке когда <= 64KB

При append новый слайс аллоцируется на куче

Функция clear зануляет все элементы слайса

Укзатель на массив в пустом слайсе указывает туда же, куда и пустая структура

Пустой слайс стоит проверять через len() == 0

### Строки

Представляют собой структуру stringStruct (reflect.SliceHeader):

* Указатель на массив байт (хранится в UTF-8)
* Длина массива (в байтах)

Для длины строки из UTF-8 символов стоит использовать utf8.RuneCountInString

Работает так же, как и слайс, но нельзя увеличить размер (создется новая строка)

Можно взять срез - создает новую строку

Индекс берется в байтах (не рунах)

range итерируется по рунам

Конкатенация создает новые строки, так что лучше пользоваться strings.Builder, которые работает со слайсом байт

При конвертации строки в слайс не создается новая область память, если строка не изменяется. При изменении слайса
компилятор создает новый слайс (оптимизация компилятора)

### Мапы

Хеш-таблица ключ-значение на связных списках (бакетах)

Чтение за константу

Ключ должен быть comparable: все, кроме slice, map, func. Для интерфейсов реализация должна быть comparable, иначе
паника.
У comparable типов опеределена хеш-функция и операция ==

Все операции через unsafe.Pointer (дженерики не нужны), информация о типе лежит в дескрипторе типа (хеш-функция, функция
сравнения, копирование)

Является указателм на структуру hmap:

* размер
* количество бакетов (логарифм, ускоряет операции)
* hash seed (рандомизирует хеш). Меняется, если после удалении длина равна 0 (безопасность)
* указатель на список бакетов

Бакеты:

* Биты младшего порядка - по ним опеределяется в какой бакет попадает ключ (берется от хеша ключа)
* Колизия - элементы попадают в один бакет
* Внутри хранится максимум 8 элементов
* Для каждого ключа хранятся биты высшего порядка в отдельном списке
* Хранятся сами ключи и значения: сначала ключи, потом значения, чтобы не было фрагментации данных

Алгоритм поиска:

* Сначала берется хеш функция от ключа и от нее последние биты LOB (логарифм от количества бакетов)
* По LOB опеределяется в каком бакете может храниться значение
* Внутри бакета по первым битам (HOB) проверяется, есть ли искомый ключ в бакете
* Если HOB найден, находим принадлежащий ему ключ и сравниваем уже сам ключи

Алгоритм добавления:

* Если в бакете уже хранится 8 элементов, то создается новый бакет и указатель на него записывается в старый
* Чтобы не было много переполняемых бакетов, происходит эвакуация
    * При средней заполняемости бакетов в 6.5 элементов или при большом количестве переполненных бакетов
    * Количество бакетов увеличивается в два раза
    * Выполняется при добавлении/удалении элемента
    * При удалении количество бакетов не уменьшается
    * Эвакуация происходит небольшими порциями (до 2 бакетов)
    * Чтение будет смотреть в старые бакеты (если эвакуация не завершена) и в новые бакеты

При асинхронном чтении и записи происходит паника, чтобы не было undefined behavior

Нельзя брать указатель на элемент мапы, так как оно может быть эвакуировано

Итерация:

* Идет как по старым, так и по новым бакетам
* В начале рандомно выбирает номер первого бакета, поэтому порядок обхода случайный
* Если в мап были добавлены элементы, то они могут как быть в итерации, так и не быть
* Если из мапа были удален элемент, по которой не было итерации, то итерации по нему не будет
* fmt.Println сортирует мап

### Интерфейсы

Структура iface:

* data - указатель на хранимые данные (объект реализации)
* itab - информация об интерфейсы
    * Информация о статическом типе интерфейса (сигнатуры методов, ...)
    * Динамический тип хранимого интерфейсом значения (тип реализации)
    * Хеш - для быстрой конвертации типов (type switch, type assert)
    * Список методов динамического типа (указатель на список указателей на методы), удовлетворяющих интерфейсу (методы
      реализации)
        * Список функций динамического типа (реализация), которые должны быть вызваны, когда вызывается методы
          статического типа (интерфейс)

У пустого интерфейсы сохраняются только указатель на реализацию и тип реализации 

На этапе компиляции генерируются метаданные каждого статического типа и интерфейса (со списоком методов).

При компиляции и в рантайме

* Сравниваются списки методов типа и интерфейса
* Создается и кешируется itab

В большинстве случаев обертка в интерфейс вызывает аллокацию на куче

Сравнение с nil:

* Значение по умолчанию для интерфейса nil
* Если положить в интерфейс объект реализации со значением nil, то объект интерфейса не будет равен nil

Type assertion `value.(T)`:

* Проверяет, что `value != nil`
* Если T не интерфейс, то проверяем, что динамический тип value равен T
* Если T интерфейс, то проверяем, что динамический тип value реаилзует T

Type cast `T(value)` - можем привести один тип к другому, если другой тип реализует старый тип

### Многопоточка

Race condition - незащищенный доступ на чтение и запись нескольких потоков к одной и той же области памяти

Флаг --race обнаруживает гонки

* Может не найти гонки, но найденные гонки валидны
* Доп нагрузка на рантайм
* Под капотом Thread sanitizer algorithm

deadlock - взаимная блокировка. Бесконечное ожидание ресурсов, занятых несколькими потоками, когда ни один из них не
может продолжать выполнение. Отлавливается, когда нет запущенных потоков (можно не отловить если еще есть горутины). Это
фатальная ошибка, нельзя отловить через defer.

Проверка дедлока запускается в функции checkdead (проверяет, есть ли хотя бы один запущенный M). Саму функцию запускает
sysmon, также запускается при запуске/остановке/завершении потока

Mutex - примитив синхронизации, обеспечивающий экслюзивный доступ к критической секции

* Lock - блокирует все другие операции Lock. Ждет, пока мьютекс не освободится
* TryLock - тот же Lock, только не ждет разблокировки мьютекса, а возвращает флаг, получилось ли его захватить
* Unlock - разблокировка. Паникует, если не было блокировки

RWMutex - мьютекс, которые разделяет блокировка на чтение и запись. Позволяет конкуретно читать, но синхронно писать

* RLock/TryRLock/RUnlock - блокировка на чтение. Не блокирует другие операции на чтение. Блокирует и может быть
  заблокирована операцией на запись
* Lock/TryLock/Unlock - блокировка на запись. Блокирует и может быть заблокирована всеми операциями

sync.Map:

* Потокобезопасная хеш-таблица
* Используется, когда много операций чтения, и ключи стабильны (не обновляются часто)
* На малом количестве потоков проигрывает мьютексу, но на большом выигрывает
* Читает из одной мапы, пишет в другую

cache contention - одновременный доступ к заблокированной мьютексом области большого количества ядер

* При взятии RW мьютекса машинный поток удаляет адрес КС в других ядрах
* При большом количестве потоков каждое ядро ждет инвалидации кеша, что приводит к большим задержкам

Context switching - при приостановке выполнения на ядре одной задачи необходимо сохранить ее контекст (чтобы потом
продолжить с того же места) и поменять его на контекст другой задачи

#### Горутины

Параллелизм - параллельное выполнение на физическом уровне (одновременное выполнение задач на разных ядрах)

Конкурентность - выполнение задачи не ожидая завершения выполнения других задач.

Горутины - легковестный поток. Является абстракцией Go, а не ОС. Лежат в пользовательском пространстве, а не в
пространстве ядра

* Можно создавать большое число
* Контролируются на уровне программы
* Выполняются конкурентно, но необязательно параллельно. На одном ядре может выполнять несколько горутин. Нет частого
  context switching

#### Каналы

Механизм синхронизации горутин. Представляет собой FIFO коллекцию

API:

* Объявление ()
    * Через make(chan Type, buf), по умолчанию nil
    * Чтение/запись без инициализации вызывает deadlock
    * Закрытие без инициализации вызывает панику
* Запись
    * Буферизированный - запись блочится, если буфер переполнен, и ждет чтения
    * Небуферизированный - запись блочится сразу и ждет чтения
    * Если нет читателей, то происходит дедлок
    * В закрытый канал происходит паника
* Чтение
    * ПОток блокируется, пока значение не будет прочитано (можно обойти через select)
* Закрытие канала
    * Сигнализирует о том, что значение больше не будет записано
    * Закрытие закрытого канала вызывает панику
    * Чтение из закрытого канала вернет значение по умолчанию (вторым аргументом false)
    * Можно повторно читать из закрытого канала
* Select позволяет читать/писать сразу из нескольких каналов
    * Сначала сработает тот case, для которого значение записалось первым
    * Если доступно несколько значений, то case случайно выбирает значение
    * default вызывается, если ни один case не сработал (отсутствие блокировки)

Аксиомы

| Действие с каналом            | Паника | Deadlock | Значение по умолчанию |
|-------------------------------|--------|----------|-----------------------|
| Чтение из nil                 |        | +        |                       |
| Запись в nil                  |        | +        |                       |
| Закрытие nil                  | +      |          |                       |
| Чтение из закрытого           |        |          | +                     |
| Повторное Чтение из закрытого |        |          | +                     |
| Запись в закрытый             | +      |          |                       |
| Повторное закрытие            | +      |          |                       |

Указатель на структуру hchan:

* Количество элементов в буффере
* Размер буфера
* Флаг, закрыт ли канал
* Указатели на список горутин на чтение/запись
* Мьютекс - отвечает за потокобезопасность доступа к буферу
* recvx/sendx - Номер ячейки буфера, откуда происходит чтение/запись
* Ссылка на буффер - кольцевая очередь, чтобы не надо было сдвигать элементы при чтении

##### Запись в канал:

* Для Буферизированного канала данные копируются в буфер
    * Если есть ожидающие горутины, то данные не идут в буфер и сразу отправляются в стек горутины из recvq
* Для небуферизированного канала данные сразу перемещаются в стек читателя

При чтении данные копируются из очереди и удаляются из нее

При переполнении буфера пишущая горутина ставится на паузу:

* Функция отправки данных в канал говорит планировщику поменять статус горутины на waiting
* Разрывает связь горутины с потоком ОС
* Планировщик отдает поток ОС другой горутине
* Ожидающая горутина кладется в очередь горутин на запись sendq
    * Хранится сама горутина и элемент, которые надо отправить в канал

###### Чтение из канала:

* Сначала получаетз значение из очереди, куда указывает recvx, и смещаем recvx на след элемент
* Если есть спящая горутина
    * Закинет элемент в буфер, куда указывает sendx, и смещаем sendx на след элемент
    * Поменяет состояние спящей горутины на runnable (помещает в очередь готовых к запуску горутин)
* Если буфер пустой, то горутина кладется в очередь recvq с адресом, куда положить данные

###### Select

* Случайно отсортирует case
* ПОследовательно проходится по каждому case
* При наличии default не будет перевода горутины в статус ожидания

##### Закрытие канала

* Флаг закрытого канала устанавливается в true
* Освобождаются все читатели - очищается очередь читателей
* Освобождаются все писатели - очищается очередь писателей
* Разблокировка всех писателей и читателей

#### Scheduler

* M - машинный поток. Связь с потоком ОС
* P - processor - хранится очередь горутин. Максимум 256 горутинг в очереди
* G - горутины.

При запуске горутины

P отдает G на выполнение M

У P есть локальная очередь (lock-free), куда в первую очередь закидываются горутины

При отсутствии горутин в очереди у P, он начинает "воровать" горутины у других P. Рандомно выбирает P 4 раза.
Берется половина горутин из другого потока

Сначала горутины помещаются в одноэлементный стек. Если там была горутина, то она переносится в очередь.
В первую очередь выполняем горутины на стеке, а потом в очереди. Так как последняя горутина скорее всего будет иметь
общие данные и переключаться на последнюю горутину будет быстрее (будет использоваться кеш процессора).
Когда гортину выполняется долго, она вытесняется из стека

Когда передается системный вызов рантайм передает управление ОС (поток блокируется). Планировщик открепит M от P, если
поток будет заблокирован на syscall в течение долгого времени
Чтобы не было блокировок горутины существует глобальная очередь, куда закидываются горутины, которые готовы на
исполнение и при этом нет свободных процессоров

Сначала смотрится локальня очередб, потом очереди других процессоров, затем глобальная. Если там нет значений, то
полится сеть. Глобальная так же проверяется
каждый 61 такт работы планировщика

При старте создает пул потоков (thread pool) - резервация потоков ОС. Там хранятся все доступные потоки ОС. Туда же
попадают потоки ОС, которые выполнили долгий syscall

Для сетевых вызовов существует netpoller:

* Туда закидываются горутины, которые ждут сетевого вызова
* Когда сетевой ответ пришел он будит горутину и закидывает ее в глобальную очередь

sysmon - поток, который управляет GC и проверяет, что если горутина работает долго (10 мс), то переключает процессор на
другую горутину (кооперативно-вытесняющая многозадачность). Он учитывает, что горутина в safe пространстве (данные могут
безопасно очиститься сборщиком мусора). Работает каждые 20мкс, увеличивая задержку до 10мс

* Кооперативная многозадачность - поток сам передает управление другому потоку
* Вытесняющая многозадачность - есть координатор, который сам переключает активный поток

Мьютексы не используют мьютексы ОС, чтобы не блокировать M. При вызове мьютекса блокируется только горутина

Состояния горутин:

* Running - выполняется на М
* Runnable - готова к выполнению (лежит в очереди)
* Waiting - заблокирована (syscall, mutex, ждет каналы)

Все заблокированные горутины лежат в wait queue

При разблокировке мьютекса в первую очередь смотрим wait queue (режим голодания)

Основные компоненты:

* G, M, P
* Локальная очередь
* Глобальная очередь
* sysmon
* Thread pool
* net poller
* wait queue

### Graceful Shutdown

Завершение приложения в контролируемом порядке: завершение всех процессов, освобождение ресурсов, обеспечение
целостности данных

Реализация:

* Слушаем сигналы ОС (interrupt, terminate) через signal.Notify или signal.NotifyContext
* В отдельной горутине запускаем сервис
* При отлавливании сигнала вызываем закрытие сервиса (например `http.Server.Shutdown(ctx)`)
    * Для закрытия создаем отдельный контекст с таймаутом, чтобы не ждать зависших сервисов
    * `http.Server` сначала закрывает соединения для новых запросов, закрывает неактивные соединения и ждет, пока не
      завершатся текущие

### Алокатор

Стек:

* Непрерывная область памяти
* Создается для каждой горутины
* Для каждой (если она не инлайнится) функции создается стекфрейм и кладется на стек
* После завершения функции стекфрейм очищается
* После заверешения горутины очищается весь стек
* Очищение/создание происходит быстро, так как данные располагаются последовательно и достаточно сдвинуть указатель на
  новое место
* Стек создается на хипе и может как расти (стек копируется и все указатели меняют адрес), так и сужаться.

Хип:

* Данные находятся в случайном месте, непоследовательно, поэтому размер не ограничен, но для очистки приходится
  последовательно пройтись по каждому
* Основан на TCMalloc
    * Память представлена в виде слоев
    * У каждого потока есть свой кеш, куда обращается только он (нет блокировки)
* Го сразу просит большой кусок памяти (арена), чтобы не было много запросов памяти у ОС
* Если арена заканчивается, то просится еще арена
* Размер арены 64MB для unix 64-bit, для остальных 4MB
* Арена делится на страницы по 8KB, которые объединяются в спаны
* В арене выделены спаны для каждого класса объекта (8 байт, 16 байт, ..., 32 KБ; всего 67), чтобы избежать фрагментации
    * Фрагментация - доступная память разбивается на небольшие несмежные блоки, которые по размеру меньше, чем
      необходимая непрерывная область
    * Спаны соединены в связный список

Арена делится на несколько списков спанов (mcentral) для каждого класса

На каждый тред создается кеш с выделенными спанами: в одной части находятся указатели, в другой - значения, для GC.

Есть 3 типа объектов, для которых по-разному работает аллокатор:

* Tiny - меньше 16B и не указатель. Сначала пытается сохраниться в кеш, если есть незаполненное место. Если места нет,
  то в кеш добавляются спаны из общего хипа
* Small - меньше 32KB. Пытается сохранить в кеш, только если есть незаполненный спан, иначе берет спан из общего хипа и
  сохраняет его в кеш
* Large - больше 32KB. Не сохраняет в кеш, а сразу сохраняет в глобальном хипе

Выделяется на хипе, когда:

* Возврат по указателю
* Аргумент является пустым интерфейсом
* Размеры значения превышают размер стека
* Если вложенные поля создаются на куче, то и вся структура создается на куче

Escape analysis - механизм определения, где выделить память: на стеке или на хипе:

* Строится граф весов
    * Нода - переменная
    * ребра - присваивание
    * вес ребер - тип присваивания
        * 0 - обычное присваивание
        * -1 - берется указатель
        * 1 - разыменование
* Обход графа и поиск переменных для аллокации на хипе
* Проставляется escap флаг

Инлайнинг - встраивание кода функции в другую функцию, что не вызывает создание отдельного стекфрейма.
Много инлайнить нельзя, так как увеличиться время компиляции и вес приложения

PGO в Go - на основе профиля кода (pprof на реальных нагрузках) компилятор понимает, какие функции стоит дополнительно
заинлайнить (в будущих версиях мб что-то еще).

#### Сборщик мусора

Удаляет данные из кучи

Забирает 25% CPU

Используем Mark and Sweep с применением трехцветного алгоритма

Трехцветный алгоритм:

Рассматривает все объекты в виде графа

* Изначально все элементы белые (незатронутые, потенциально ненужные объекты)
* Покрасить все корневые элементы (стек и глобальные переменные) в серый (на рассмотрении)
* Выбрать серый объект из помеченных и пометить его черным (активным объектом)
* Все объекты, на которые указывает черный объект, пометить серым (поиск в ширину).
* Если в графе остались серые объекты, то начать сначала (выбрать черный объект)

Алгоритм Mark and Sweep:

* Остановить ненадолго выполнение программы (Stop The World)
    * Останавливаются все горутины
    * Не ждет горутины в syscalls
    * Переключает рантайм в режим Marking
    * Включает Write Barrier. Все новые объекты помечаются серым
* Разметить объекты в куче (трехцветный алгоритм). Работает асинхронно
* Еще раз остановить выполнение программы и удалить белые объекты
* Выключить Write Barrier

GC запускается, когда:

* Ручной запуск runtime.GC()
* Когда память увеличивается на процент, указанный в переменной окружения GOGC
    * Если -1, то GC никогда не запустится
    * По умолчанию 100
    * Сравнивает с памятью после прошлого запуска
* При превышении объема память, указанном в GOMEMLIMIT
    * Не ограничивает полностью память
    * При резком росте, планировщик может не успеть сработать
* Раз в 2 минуты
    * Если планировщик не отключен

Scavenger - компонент рантайма Go, который говорит ОС, что оперативная память больше не нужна процессу (не освобождает
сразу). Работает в отдельной горутине.
Старается тратить не больше 1% CPU, но при приближении к GOMEMLIMIT тратит до 10%

## БД

Порядок выполнения запроса: FROM, JOIN, ON, WHERE, GROUP BY, HAVING, ORDER BY, OFFSET, LIMIT

[//]: # (TODO: Репликаци и шардирование)

## Репликация

Дублирование данных на разных серверах

* Повышение отказоустойчивости
* Повышение производительности

WAL - журнал предзаписи транзакции. Изменения сначала записываются в журнал, а затем на диск, чтобы можно было
восстановиться в случае сбоя. Используется также для репликации

Виды репликации:

* Физическая (потоковая) - от основного сервера на реплики передается WAL. Одна версия ОС, СУБД и архитектуры. Подходит
  для надежности
    * Асинхронная (по умолчанию) - сначала записываем в мастер, не ждем, пока записи применятся на репликах. Данные
      могут не сохраниться, но зато быстро
    * Синхронная - сначала записываем в WAL хотя бы одной реплики, только потом в мастер. Надежно, но долго
        * Настраивается через synchronous_standby_names = `ANY|FIRST {number} ({servers})`
* Логическая - синхронизаця на основе идентификатора с использованием модели publish-subscribe
    * Отправляет подписчикам измененный строки
    * Реплицирует только данные, структуру изменять не может

### Транзакции

Транзакция - последовательность операций со следующими свойствами (ACID):

* Атомарность - либо все операции в транзакции выполнятся полностью, либо не выполнится ни одной
* Согласованность - каждая успешная транзакция фиксирует только допустимый результат (нет промежуточных состояний, до и
  после БД согласована)
* Изоляция - параллельные транзакции не должны оказывать влияние друг на друга
    * Блокировки (строки, таблицы)
    * Версии - при каждом обновлении создается новая версия данных. До коммита все читают старую версию
* Надежность - после успешного выполнения транзакции ее изменения не будут отменены ввиду различных сбоев

Аномалии транзакций:

* Грязное чтение - транзакция читает данные, записанные незавершенной транзакцией
* Неповторяемое чтение - транзакция читает данные, которые другая транзакция успела изменить до ее завершения
* Фантомное чтение - набор строк изменился после первого прочтения транзакцией (появились/исчезли данные)
* Потерянное обновление - одно из параллельных транзакций затрется другой

Уровни изоляции:

* Read uncommited (незафиксированное чтение) - отсутствие транзакции. Другие транзакции видят незафиксированные
  изменения. (Отсутствует в Postgres)
* Read commited (зафиксированное чтение) - транзакции видят изменения только завершенных транзакций (по умолчанию в
  Postres)
* Repeatable read (повторяемое чтение) - транзакция не увидит результат транзакций, завершенных во время ее выполнения.
  Создается snapshot
* Serializable - все транзакции выполняются последовательно

MVCC (multi-version concurrency control) - БД хранит несколько версий одного объекта для каждой транзакции. В Postgres
есть Snapshot Isolation

CAP-теорема - в распределенной системе можно добиться только 2 из 3 свойств:

* Согласованность - во всех узлах актуальные данные
* Доступность - способность поддерживать работоспособность даже в условиях сбоев
* Устойчивость к разделению - система продолжит работу, даже если данные находятся на изолированных узлах

### Индексы

Индекс - объекты БД, предназначенные для быстрого доступа к данным. Ускоряет чтение, но замедляет запись, так как
необходимо перестроить индекс (сначала обновить данные, затем перестроить индексы)

Создание индекс навешивает блокировку на запись. Чтобы не блокировать таблицу, надо указать СONCURRENTLY при создании
индекса:

* Работает медленнее (ждет заврешения всех транзакций)
* Не работает в транзакции (может оставить после себя невалидные индексы, надо перезапускать создание)

Кластеризованный индекс - использует первичный ключ. Данные в таблице уже отсортированы по первичному ключу. Использует
алгоритм бин поиска
Некластеризованный индекс - хранится отдельно от данных. Создается вручную

Виды индексов Postgres:

* Hash
    * Работают только с операцией =
    * Использует хеш-функцию
* B-Tree
    * Работают с операциями =, >, <. Применяются также при фильтрации по вхождению в начало строки, сортировке
    * Используют сбалансированное ветвистое дерево, внутри узлов которого находятся отсортированные массивы
    * В PostgreSQL по умолчанию
* Gist
    * Сбалансированное обобщенное дерево поиска
    * Неотсортированные элементы
    * Применяются при поиске геоданных
    * Работают для операцией с координатами (слева <<, справа >>, выше >>|, ...)
* Sp-Gist
    * Space partitioning - разбиение пространства
    * Работает со структурами, которые рекурсивно разделяются на непересекаемые множества: дерево квадрантов, k-мерные
      деревья, префиксные деревья
    * Можно реализовать префиксное дерево поиска строк
* Gin
    * Обратный индекс - для каждого ключа из коллекции объектов приведен список объектов, в которых встречается этот
      ключ
    * Составные типы данных, доступ к которым происходит через ключи: массивы, jsonb, tsvector (отсортированный список
      лексем)
    * Используется для полнотекстового поиска
* Brin
    * Индекс зоны блоков
    * Для тех данных, значение которых коррелирует с физическим расположением в таблице
    * Операции сравнения, кроме неравенства
    * Подходит например для логов, трекинга GPS, измерения сенсоров, аналитические запросы: фильтрация по временному
      промежутку (временные ряды)
    * Хранит блоки данных (несколько страниц) с минимальным и максимальным значением внутри блока

Способы сканированияя (через EXPLAIN):

* Seq Scan - последовательное сканирование. Индексы не используются
* Index Scan - данные ищутся с помощью индексов. Обращаются к таблице данных для определения области видимости.
* Index Only Scan - когда выбираются данные только из индекса. Нет фильтрации и выборки полей вне индекса
* Bitmap Scan - строится битовая карта по нескольким индексам

## Кафка

Алгоритм:

* Продюсер отправляет сообщение
* Консьюмер запрашивает данные из кафки (pull модель)
* Кафка возвращает сообщение и идентификатор брокера
* Брокер помечает сообщение in-flight (в обработке). Оно не отправляется другим консьюмерам
* Консьюмер отправляет запрос брокеру (по идентификатору) об удачной/неудачной отправке (комитит офсет)

Основные определения:

* Сообщение (record) - отправляемые данные
    * Key - выбор партиции (опциональный)
    * Значение - содержимое (массив байт)
    * Timestamp - время сообщенияё (при отправке или обработке внутри кластера)
    * Headers - заголовки. Набор key-value пар
* Топик - способ группировки сообщений по категориям
* Партиция - FIFO очередь из сообщений внутри топика
    * Может быть несколько для распределения нагрузки. В таком случае не будет строгой очередности сообщений
    * Можно в сообщении указать ключ, тогда на основе него будет выбрана партиция, что приводит к соблюдению очередности
    * Возможна репликация с дублированием сообщений
    * Обозначается целым числом
* Офсет - какое следующее сообщение кафка отправит потребителю
* Консьюмер группа - несколько потребителей, связанных одной логикой. Например несколько инстансов одного сервиса
    * Каждый консьюмер внутри читает из своей партиции
    * Один офсет в рамках группы, чтобы избежать дублирования чтения
* Zookeeper - отдельный сервис, отвечающий за хранение метаданных

По умолчанию по брокерам балансируются партиции независимо от топиков (в некоторых брокерах может не быть партиций из
топика). Такое поведение можно конфигурировать

Данные хранятся в log-файлах:

* segment.log - сам данные с оффсетом
* segment.index - маппинг оффсета на позицию сообщения (в байтах)
* segment.timeindex - маппинг timestamp на оффсет для чтения сообщений по времени, а не по оффсету
* segment - строится по первому оффсету сообщения.
    * Каждый файл имеет ограничение по размеру (по умолчанию 1GB)
    * Хранит timestamp - максимальное время сообщения (удаляется по умолчанию через неделю)

Данные хранятся в кафке, пока не превысится лимит по времени или по памяти (устанавливается при настройке). Удаляется
сразу сегмент целиком

Брокеры можно реплицировать. Один из брокеров является контроллером, который назначает лидер-реплики. Читать и писать
можно только из лидера/в лидер

При нагруженномсти slave топиков кластер можно перебалансировать.

insync реплика - лидер синхронно записывает данные в реплики. Такие брокеры могут стать лидерами. Количество
nsync-реплик конифгурируется (обычно на единицу меньше, чем количество брокеров). Остальные

Гарантии доставки:

* At least once
    * Ручной коммит сообщений на консьюмере
    * acks=1/-1 на продьюсере
* At most once
    * Автокоммит сообщений на консьюмере
    * acks=1
* Exactly once
    * Идемпотентность операций
    * Ставим оффсет вручную, а не из оффсет-топика

acks=0 - не ждем подтверждение от брокера при отправке
acks=1 - ждем подтверждение от лидер-реплики (могут теряться сообщения, если брокер с лидер-репликой упал)
acks=-1 - ждем подтверждение от лидера и от insync-реплик

Отправка сообщения:

* Отправляем запрос в zookeeper через брокера, чтобы узнать информацию о репликах
* Сереализуем сообщение
* Определить партицию
    * Round-robin - по умолчанию
    * Конкретный номер партиции
    * На основе ключа (хеш с остатком от деления)
* Сжатие сообщение (опционально)
* Собрать сообщения в батчи

## Протоколы

Стек TCP/IP. Уровни:

* Прикладной - работа приложений с сетью
* Транспортный - для какого приложения данные, гарантия надежности (не у UDP)
* Сетевой - в какую сеть данные
* Канальный - передача на физическом уровне

TCP - протокол управления передачей. Протокол транспортного уровня с гарантированной доставкой пакетов

Сначала устанавливает TCP Handshake:

1. КЛиент отправляет сервере пакет с флагом SYN
2. Сервер отправляет клиент пакет с флагами SYN ACK
3. Клиент подтверждает серверу получение пакета отправкой нового пакета с флагом ACK

Завершение tcp соединения:

* Флаг FIN - все данные отправлены успешно
* Флаг RST - сброс соединения

UDP - протокол пользовательских датаграм

* Не требует подтверждения получения
* Гарантирует целостность единого сегмента
* Не гарантирует порядок
* Быстрый
* Используется в DNS, отправке видео, аудио

DNS - сервис доменных имен. Возвращает ip-адрес по доменному имени. IP можно найти в следующих серверах: браузер,
ОС, интернет-провайдеры, корневые DNS-сервера (дают адрес DNS-сервера конкретной доменной зоны. ВСего 13, но копии есть
в разных странах и городах)

HTTP - протокол передачи гипертекста. Прикладной уровень TCP/IP. Формат передачи данных

[//]: # (TODO: Работа)

HTTPs - защищенный HTTP. Использует шифрование пакетов через криптографические протоколы TLS (на смену SSL). Проверяет
сертификат на клиенте и сервере для валидации владельца сервера. Данные Сложно перехватить и невозможно прочитать или
переписать

Ассиметричное шифрование:

* Публичный ключ для шифрования. Отправляется клиенту
* Приватный ключ для дешифрования. Хранится на сервере
* Сложная реализация, увеличение времени, но безопасно

Симметричное шифрование:

* Один секретный ключ для шифрования и дешифрования
* Сложность в безопасной передаче ключа и хранении

Комбинированное шифрование (используют защищенные протоколы):

* Передаем ключ симметричного шифрования с помошью ассиметричного шифрования
* Передаем данные через симметричное шифрование

Алгоритм:

* Клиент отправляет запрос с версиями алгоритма шифрования
* Сервер возвращает сертфикат
* Клиент проверяет подлинность сертификата
* Клиент запрашивает у сервера публичный ключ
* Браузер шифрует публичным ключом свой сеансовый ключ и передает серверу
* Сервер приватным ключ расшифровывает сеансовый ключ
* Клиент и сервер обмениваются данными, зашифрованными через сеансовый ключ

Ключи генерируются с помощью алгоритма RSA, передаются с помощью алгоритма Диффи-Хеллмана

HTTP/2:

* Использует тот же набор данных (методы, ресурсы, заголовки, ...)
* Бинарный - отправляет данные не в виде текста, а в виде массива байт
* Сжимает данные
* Каждое сообщение состоит из набора фреймов
    * Длина
    * Тип: заголовок, тело запроса, ...
    * Флаги
    * идентификатор потока
    * Данные
* Stream - последовательность фреймов с одинаковым идентификатором стрима
    * В рамках одного соединения может быть несколько стримов
    * Строгий порядок фреймов в рамках одного стрима
* Для нескольких запросов можно использовать одно соединение
    * Каждое новый запрос создает стрим
    * Мультиплексирование - передача данных в две стороны
* Можно прервать отправку запроса - закрыть стрим с помощью специального фрейма
    * В HTTP 1.1 можно было только разорвать соединение
* Приоритизация стримов через специальный фрейм
* Server push - может отправлять в сторону клиента запросы без инициирующего запроса со стороны клиента (нужно
  разрешение)

gRPC - фреймворк для работы с удаленным вызовом процедур (RPC)

* Отправляет данные через HTTP/2
* Типы методов
    * Unary - один запрос, один ответ
    * Server streaming - клиент отправляет один запрос, сервер возвращает поток ответов. Например, отправка логов
    * Client Streaming - клиент отправляет поток запросов и ждет ответ сервера. Например, загрузка файла
    * Bidirectional streaming - двусторонний обмен потоками данных. Например, чат
* Можно отправлять метаданные в отдельном канале (аналог заголовков)

Protobuf - язык описания определния интерфейса, который используется в gRPC

